{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1. Load the libries and Data For the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Store StoreType Assortment  CompetitionDistance  CompetitionOpenSinceMonth  \\\n",
      "0      1         c          a               1270.0                        9.0   \n",
      "1      2         a          a                570.0                       11.0   \n",
      "2      3         a          a              14130.0                       12.0   \n",
      "3      4         c          c                620.0                        9.0   \n",
      "4      5         a          a              29910.0                        4.0   \n",
      "\n",
      "   CompetitionOpenSinceYear  Promo2  Promo2SinceWeek  Promo2SinceYear  \\\n",
      "0                    2008.0       0              NaN              NaN   \n",
      "1                    2007.0       1             13.0           2010.0   \n",
      "2                    2006.0       1             14.0           2011.0   \n",
      "3                    2009.0       0              NaN              NaN   \n",
      "4                    2015.0       0              NaN              NaN   \n",
      "\n",
      "     PromoInterval  \n",
      "0              NaN  \n",
      "1  Jan,Apr,Jul,Oct  \n",
      "2  Jan,Apr,Jul,Oct  \n",
      "3              NaN  \n",
      "4              NaN  \n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVC, LinearSVC,SVR\n",
    "from sklearn.metrics import r2_score\n",
    "import xgboost as xgb\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Modelling Helpers\n",
    "from sklearn.preprocessing import Imputer , Normalizer , scale\n",
    "from sklearn.cross_validation import train_test_split , StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "\n",
    "# Metrics\n",
    "\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "\n",
    "# Configure visualisations\n",
    "%matplotlib inline\n",
    "mpl.style.use( 'ggplot' )\n",
    "sns.set_style( 'white' )\n",
    "pylab.rcParams[ 'figure.figsize' ] = 8 , 6\n",
    "\n",
    "store = pd.read_csv('./input/store.csv')\n",
    "train = pd.read_csv('./input/train.csv')\n",
    "test = pd.read_csv('./input/test.csv')\n",
    "\n",
    "print store.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_map(features):\n",
    "    outfile = open('xgb.fmap', 'w')\n",
    "    for i, feat in enumerate(features):\n",
    "        outfile.write('{0}\\t{1}\\tq\\n'.format(i, feat))\n",
    "    outfile.close()\n",
    "    \n",
    "def normalize(x):\n",
    "\n",
    "    xmin = x.min()\n",
    "    xmax = x.max()\n",
    "    \n",
    "    x = (x-xmin)/(xmax-xmin)\n",
    "\n",
    "    return x\n",
    "\n",
    "def rmspe_score(y_true,y_pred):\n",
    "    return 'RMSPE',np.sqrt(np.mean((1-y_pred/y_true)**2))\n",
    "\n",
    "def minmaxscaler(df):\n",
    "    return \n",
    "\n",
    "def plot_correlation_map( df ):\n",
    "    corr = df.corr()\n",
    "    _ , ax = plt.subplots( figsize =( 12 , 10 ) )\n",
    "    cmap = sns.diverging_palette( 220 , 10 , as_cmap = True )\n",
    "    _ = sns.heatmap(\n",
    "        corr, \n",
    "        cmap = cmap,\n",
    "        square=True, \n",
    "        cbar_kws={ 'shrink' : .9 }, \n",
    "        ax=ax, \n",
    "        annot = True, \n",
    "        annot_kws = { 'fontsize' : 12 }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_features(features):\n",
    "    features = pd.get_dummies(features,columns=['DayOfWeek','StoreType','Assortment','PromoInterval'])\n",
    "    features['StateHoliday'].replace('a',1,inplace=True)\n",
    "    features['StateHoliday'].replace('b',2,inplace=True)\n",
    "    features['StateHoliday'].replace('c',3,inplace=True)\n",
    "    features['StateHoliday'] =  pd.to_numeric(features['StateHoliday'], downcast='integer')\n",
    "    features['StateHoliday'] = normalize(features[\"StateHoliday\"])\n",
    "    features['Date'] = pd.to_datetime(features['Date'])\n",
    "    features['CompetitionOpenSinceMonth'] = pd.to_numeric(features['CompetitionOpenSinceMonth'], downcast='integer')\n",
    "    features['CompetitionOpenSinceYear'] = pd.to_numeric(features['CompetitionOpenSinceYear'], downcast='integer')\n",
    "    features['Month'] = features['Date'].map(lambda x: x.month)\n",
    "    features['Year'] = features['Date'].map(lambda x: x.year)\n",
    "    features['Week'] = features['Date'].map(lambda x: x.strftime(\"%V\"))\n",
    "    features['Week']=pd.to_numeric(features['Week'], downcast='integer')\n",
    "    features[\"CompetitionMonthDuration\"] = (12-features['CompetitionOpenSinceMonth']+features['Month'])+(features['Year']-features['CompetitionOpenSinceYear'])*12\n",
    "    features[\"Promo2WeekDuration\"] = (53-features['Promo2SinceWeek']+features['Week'])+(features['Year']-features['Promo2SinceYear'])*53\n",
    "    features[\"CompetitionMonthDuration\"] = normalize(features[\"CompetitionMonthDuration\"])\n",
    "    features[\"Promo2WeekDuration\"] = normalize(features[\"Promo2WeekDuration\"])\n",
    "    features = features.drop(['CompetitionOpenSinceMonth','CompetitionOpenSinceYear','Promo2SinceWeek','Promo2SinceYear','Month','Year','Week','Date','Store'],axis=1)\n",
    "    if 'Customers' in features.columns:\n",
    "        features = features.drop(['Customers'],axis=1)\n",
    "    features.fillna(0,inplace=True)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('RMSPE', 0.01699552219123154)\n"
     ]
    }
   ],
   "source": [
    "store[\"CompetitionDistance\"] = normalize(store[\"CompetitionDistance\"])\n",
    "\n",
    "org_train_data = pd.merge(train,store,on='Store')\n",
    "org_test_data = pd.merge(test,store,on='Store')\n",
    "\n",
    "sales_train_raw = org_train_data[org_train_data['Sales']!=0]['Sales']\n",
    "sales_train = np.log1p(sales_train_raw)\n",
    "\n",
    "features_train_raw = org_train_data[org_train_data['Sales']!=0].drop('Sales',axis=1)\n",
    "\n",
    "features_train = build_features(features_train_raw)\n",
    "\n",
    "#print features.head()\n",
    "\n",
    "# 将'features'和'val'数据切分成训练集和测试集\n",
    "X_train, X_val, y_train, y_val = train_test_split(features_train, sales_train, test_size = 0.1, random_state = 0)\n",
    "\n",
    "xgdmat=xgb.DMatrix(X_train,y_train)\n",
    "params = {\"objective\": \"reg:linear\",\n",
    "          \"booster\" : \"gbtree\",\n",
    "          \"eta\": 0.2,\n",
    "          \"max_depth\": 12,\n",
    "          \"subsample\": 0.9,\n",
    "          \"colsample_bytree\": 0.7,\n",
    "          \"silent\": 1\n",
    "          }\n",
    "num_trees = 200\n",
    "final_gb=xgb.train(params,xgdmat,num_trees,feval=rmspe_score)\n",
    "tesdmat=xgb.DMatrix(X_val)\n",
    "y_pred=final_gb.predict(tesdmat)\n",
    "\n",
    "#print r2_score(y_val,y_pred)\n",
    "print rmspe_score(y_val,y_pred)\n",
    "\n",
    "reg = LinearRegression()\n",
    "#reg.fit(X_train,y_train)\n",
    "#y_pred=reg.predict(X_val)\n",
    "\n",
    "#print rmspe_score(y_val,y_pred)\n",
    "#print reg.score(X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = build_features(org_test_data)\n",
    "test_train = test.drop(['Id'],axis=1)\n",
    "test_result = final_gb.predict(xgb.DMatrix(test_train))\n",
    "submission = pd.DataFrame({\"Id\": test['Id'], \"Sales\": np.expm1(test_result)})\n",
    "submission.to_csv(\"my_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception AttributeError: \"'DMatrix' object has no attribute 'handle'\" in <bound method DMatrix.__del__ of <xgboost.core.DMatrix object at 0x10a2af190>> ignored\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'gbm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-90e3130e271e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcreate_feature_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mimportance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_fscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'xgb.fmap'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mimportance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimportance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gbm' is not defined"
     ]
    }
   ],
   "source": [
    "# XGB feature importances\n",
    "# Based on https://www.kaggle.com/mmueller/liberty-mutual-group-property-inspection-prediction/xgb-feature-importance-python/code\n",
    "\n",
    "create_feature_map(features)\n",
    "importance = gbm.get_fscore(fmap='xgb.fmap')\n",
    "importance = sorted(importance.items(), key=operator.itemgetter(1))\n",
    "\n",
    "df = pd.DataFrame(importance, columns=['feature', 'fscore'])\n",
    "df['fscore'] = df['fscore'] / df['fscore'].sum()\n",
    "\n",
    "featp = df.plot(kind='barh', x='feature', y='fscore', legend=False, figsize=(6, 10))\n",
    "plt.title('XGBoost Feature Importance')\n",
    "plt.xlabel('relative importance')\n",
    "fig_featp = featp.get_figure()\n",
    "fig_featp.savefig('feature_importance_xgb.png', bbox_inches='tight', pad_inches=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
