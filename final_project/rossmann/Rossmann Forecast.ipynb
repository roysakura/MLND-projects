{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1. Load the libries and Data For the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roy/Documents/workplace/env/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Store StoreType Assortment  CompetitionDistance  CompetitionOpenSinceMonth  \\\n",
      "0      1         c          a               1270.0                        9.0   \n",
      "1      2         a          a                570.0                       11.0   \n",
      "2      3         a          a              14130.0                       12.0   \n",
      "3      4         c          c                620.0                        9.0   \n",
      "4      5         a          a              29910.0                        4.0   \n",
      "\n",
      "   CompetitionOpenSinceYear  Promo2  Promo2SinceWeek  Promo2SinceYear  \\\n",
      "0                    2008.0       0              NaN              NaN   \n",
      "1                    2007.0       1             13.0           2010.0   \n",
      "2                    2006.0       1             14.0           2011.0   \n",
      "3                    2009.0       0              NaN              NaN   \n",
      "4                    2015.0       0              NaN              NaN   \n",
      "\n",
      "     PromoInterval  \n",
      "0              NaN  \n",
      "1  Jan,Apr,Jul,Oct  \n",
      "2  Jan,Apr,Jul,Oct  \n",
      "3              NaN  \n",
      "4              NaN  \n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVC, LinearSVC,SVR\n",
    "from sklearn.metrics import r2_score\n",
    "import xgboost as xgb\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Modelling Helpers\n",
    "from sklearn.preprocessing import Imputer , Normalizer , scale\n",
    "from sklearn.cross_validation import train_test_split , StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "\n",
    "# Metrics\n",
    "\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "\n",
    "# Configure visualisations\n",
    "%matplotlib inline\n",
    "mpl.style.use( 'ggplot' )\n",
    "sns.set_style( 'white' )\n",
    "pylab.rcParams[ 'figure.figsize' ] = 8 , 6\n",
    "\n",
    "store = pd.read_csv('./input/store.csv')\n",
    "train = pd.read_csv('./input/train.csv')\n",
    "test = pd.read_csv('./input/test.csv')\n",
    "\n",
    "print(store.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_map(features):\n",
    "    outfile = open('xgb.fmap', 'w')\n",
    "    for i, feat in enumerate(features):\n",
    "        outfile.write('{0}\\t{1}\\tq\\n'.format(i, feat))\n",
    "    outfile.close()\n",
    "    \n",
    "def normalize(x):\n",
    "\n",
    "    xmin = x.min()\n",
    "    xmax = x.max()\n",
    "    \n",
    "    x = (x-xmin)/(xmax-xmin)\n",
    "\n",
    "    return x\n",
    "\n",
    "def rmspe_score(y_true,y_pred):\n",
    "    return 'RMSPE',np.sqrt(np.mean((1-y_pred/y_true)**2))\n",
    "\n",
    "def minmaxscaler(df):\n",
    "    return \n",
    "\n",
    "def plot_correlation_map( df ):\n",
    "    corr = df.corr()\n",
    "    _ , ax = plt.subplots( figsize =( 12 , 10 ) )\n",
    "    cmap = sns.diverging_palette( 220 , 10 , as_cmap = True )\n",
    "    _ = sns.heatmap(\n",
    "        corr, \n",
    "        cmap = cmap,\n",
    "        square=True, \n",
    "        cbar_kws={ 'shrink' : .9 }, \n",
    "        ax=ax, \n",
    "        annot = True, \n",
    "        annot_kws = { 'fontsize' : 12 }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Store     DayOfWeek         Sales     Customers          Open  \\\n",
      "count  1.017209e+06  1.017209e+06  1.017209e+06  1.017209e+06  1.017209e+06   \n",
      "mean   5.584297e+02  3.998341e+00  5.773819e+03  6.331459e+02  8.301067e-01   \n",
      "std    3.219087e+02  1.997391e+00  3.849926e+03  4.644117e+02  3.755392e-01   \n",
      "min    1.000000e+00  1.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "25%    2.800000e+02  2.000000e+00  3.727000e+03  4.050000e+02  1.000000e+00   \n",
      "50%    5.580000e+02  4.000000e+00  5.744000e+03  6.090000e+02  1.000000e+00   \n",
      "75%    8.380000e+02  6.000000e+00  7.856000e+03  8.370000e+02  1.000000e+00   \n",
      "max    1.115000e+03  7.000000e+00  4.155100e+04  7.388000e+03  1.000000e+00   \n",
      "\n",
      "              Promo  SchoolHoliday  \n",
      "count  1.017209e+06   1.017209e+06  \n",
      "mean   3.815145e-01   1.786467e-01  \n",
      "std    4.857586e-01   3.830564e-01  \n",
      "min    0.000000e+00   0.000000e+00  \n",
      "25%    0.000000e+00   0.000000e+00  \n",
      "50%    0.000000e+00   0.000000e+00  \n",
      "75%    1.000000e+00   0.000000e+00  \n",
      "max    1.000000e+00   1.000000e+00  \n",
      "-----------------\n",
      "            Store  CompetitionDistance  CompetitionOpenSinceMonth  \\\n",
      "count  1115.00000          1112.000000                 761.000000   \n",
      "mean    558.00000             0.071003                   7.224704   \n",
      "std     322.01708             0.101044                   3.212348   \n",
      "min       1.00000             0.000000                   1.000000   \n",
      "25%     279.50000             0.009197                   4.000000   \n",
      "50%     558.00000             0.030393                   8.000000   \n",
      "75%     836.50000             0.090487                  10.000000   \n",
      "max    1115.00000             1.000000                  12.000000   \n",
      "\n",
      "       CompetitionOpenSinceYear       Promo2  Promo2SinceWeek  Promo2SinceYear  \n",
      "count                761.000000  1115.000000       571.000000       571.000000  \n",
      "mean                2008.668857     0.512108        23.595447      2011.763573  \n",
      "std                    6.195983     0.500078        14.141984         1.674935  \n",
      "min                 1900.000000     0.000000         1.000000      2009.000000  \n",
      "25%                 2006.000000     0.000000        13.000000      2011.000000  \n",
      "50%                 2010.000000     1.000000        22.000000      2012.000000  \n",
      "75%                 2013.000000     1.000000        37.000000      2013.000000  \n",
      "max                 2015.000000     1.000000        50.000000      2015.000000  \n"
     ]
    }
   ],
   "source": [
    "#print train.isnull().sum()\n",
    "#print store.isnull().sum()\n",
    "\n",
    "print train.describe()\n",
    "print '-----------------'\n",
    "print store.describe()\n",
    "#print store.columns\n",
    "#index = store['CompetitionDistance'].index[store['CompetitionDistance'].apply(np.isnan)]\n",
    "#print store.describe()\n",
    "#store['CompetitionDistance'].fillna(0,inplace=True)\n",
    "#store['PromoInterval'].fillna('no',inplace=True)\n",
    "\n",
    "\n",
    "#print store[store['Promo2']==1].count()\n",
    "#sns.countplot(data=store,x='StoreType',ax=ax[0,0])\n",
    "#sns.countplot(data=store,x='Assortment',ax=ax[0,1])\n",
    "#sns.countplot(data=store,x='PromoInterval',ax=ax[0,2])\n",
    "#sns.countplot(data=store,x='')\n",
    "#sns.distplot(store.Promo2)\n",
    "#sns.distplot(store.CompetitionDistance,ax=ax[1,0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          2015-07-31\n",
       "1          2015-07-30\n",
       "2          2015-07-29\n",
       "3          2015-07-28\n",
       "4          2015-07-27\n",
       "5          2015-07-26\n",
       "6          2015-07-25\n",
       "7          2015-07-24\n",
       "8          2015-07-23\n",
       "9          2015-07-22\n",
       "10         2015-07-21\n",
       "11         2015-07-20\n",
       "12         2015-07-19\n",
       "13         2015-07-18\n",
       "14         2015-07-17\n",
       "15         2015-07-16\n",
       "16         2015-07-15\n",
       "17         2015-07-14\n",
       "18         2015-07-13\n",
       "19         2015-07-12\n",
       "20         2015-07-11\n",
       "21         2015-07-10\n",
       "22         2015-07-09\n",
       "23         2015-07-08\n",
       "24         2015-07-07\n",
       "25         2015-07-06\n",
       "26         2015-07-05\n",
       "27         2015-07-04\n",
       "28         2015-07-03\n",
       "29         2015-07-02\n",
       "              ...    \n",
       "1017179    2013-01-30\n",
       "1017180    2013-01-29\n",
       "1017181    2013-01-28\n",
       "1017182    2013-01-27\n",
       "1017183    2013-01-26\n",
       "1017184    2013-01-25\n",
       "1017185    2013-01-24\n",
       "1017186    2013-01-23\n",
       "1017187    2013-01-22\n",
       "1017188    2013-01-21\n",
       "1017189    2013-01-20\n",
       "1017190    2013-01-19\n",
       "1017191    2013-01-18\n",
       "1017192    2013-01-17\n",
       "1017193    2013-01-16\n",
       "1017194    2013-01-15\n",
       "1017195    2013-01-14\n",
       "1017196    2013-01-13\n",
       "1017197    2013-01-12\n",
       "1017198    2013-01-11\n",
       "1017199    2013-01-10\n",
       "1017200    2013-01-09\n",
       "1017201    2013-01-08\n",
       "1017202    2013-01-07\n",
       "1017203    2013-01-06\n",
       "1017204    2013-01-05\n",
       "1017205    2013-01-04\n",
       "1017206    2013-01-03\n",
       "1017207    2013-01-02\n",
       "1017208    2013-01-01\n",
       "Name: Date, Length: 1017209, dtype: object"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.merge(train,store,on='Store')\n",
    "\n",
    "train_data.isnull().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_features(features):\n",
    "    features = pd.get_dummies(features,columns=['DayOfWeek','StoreType','Assortment','PromoInterval'])\n",
    "    features['StateHoliday'].replace('a',1,inplace=True)\n",
    "    features['StateHoliday'].replace('b',2,inplace=True)\n",
    "    features['StateHoliday'].replace('c',3,inplace=True)\n",
    "    features['StateHoliday'] =  pd.to_numeric(features['StateHoliday'], downcast='integer')\n",
    "    features['StateHoliday'] = normalize(features[\"StateHoliday\"])\n",
    "    features['Date'] = pd.to_datetime(features['Date'])\n",
    "    features['CompetitionOpenSinceMonth'] = pd.to_numeric(features['CompetitionOpenSinceMonth'], downcast='integer')\n",
    "    features['CompetitionOpenSinceYear'] = pd.to_numeric(features['CompetitionOpenSinceYear'], downcast='integer')\n",
    "    features['Month'] = features['Date'].map(lambda x: x.month)\n",
    "    features['Year'] = features['Date'].map(lambda x: x.year)\n",
    "    features['Week'] = features['Date'].map(lambda x: x.strftime(\"%V\"))\n",
    "    features['Week']=pd.to_numeric(features['Week'], downcast='integer')\n",
    "    features[\"CompetitionMonthDuration\"] = (12-features['CompetitionOpenSinceMonth']+features['Month'])+(features['Year']-features['CompetitionOpenSinceYear'])*12\n",
    "    features[\"Promo2WeekDuration\"] = (53-features['Promo2SinceWeek']+features['Week'])+(features['Year']-features['Promo2SinceYear'])*53\n",
    "    features[\"CompetitionMonthDuration\"] = normalize(features[\"CompetitionMonthDuration\"])\n",
    "    features[\"Promo2WeekDuration\"] = normalize(features[\"Promo2WeekDuration\"])\n",
    "    features = features.drop(['CompetitionOpenSinceMonth','CompetitionOpenSinceYear','Promo2SinceWeek','Promo2SinceYear','Month','Year','Week','Date','Store'],axis=1)\n",
    "    if 'Customers' in features.columns:\n",
    "        features = features.drop(['Customers'],axis=1)\n",
    "    features.fillna(0,inplace=True)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2411244309045144\n"
     ]
    }
   ],
   "source": [
    "store[\"CompetitionDistance\"] = normalize(store[\"CompetitionDistance\"])\n",
    "\n",
    "org_train_data = pd.merge(train,store,on='Store')\n",
    "org_test_data = pd.merge(test,store,on='Store')\n",
    "\n",
    "sales_train_raw = org_train_data[org_train_data['Sales']!=0]['Sales']\n",
    "sales_train = np.log1p(sales_train_raw)\n",
    "\n",
    "features_train_raw = org_train_data[org_train_data['Sales']!=0].drop('Sales',axis=1)\n",
    "\n",
    "features_train = build_features(features_train_raw)\n",
    "\n",
    "#print features.head()\n",
    "\n",
    "# 将'features'和'val'数据切分成训练集和测试集\n",
    "X_train, X_val, y_train, y_val = train_test_split(features_train, sales_train, test_size = 0.1,random_state = 42)\n",
    "\n",
    "xgdmat=xgb.DMatrix(X_train,y_train)\n",
    "params = {\"objective\": \"reg:linear\",\n",
    "          \"booster\" : \"gbtree\",\n",
    "          \"eta\": 0.2,\n",
    "          \"max_depth\": 12,\n",
    "          \"subsample\": 0.9,\n",
    "          \"colsample_bytree\": 0.7,\n",
    "          \"silent\": 1\n",
    "          }\n",
    "num_trees = 50\n",
    "#final_gb=xgb.train(params,xgdmat,num_trees,feval=rmspe_score)\n",
    "#tesdmat=xgb.DMatrix(X_val)\n",
    "#y_pred=final_gb.predict(tesdmat)\n",
    "\n",
    "#print r2_score(y_val,y_pred)\n",
    "#print rmspe_score(y_val,y_pred)\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train,y_train)\n",
    "y_pred=reg.predict(X_val)\n",
    "\n",
    "#print rmspe_score(y_val,y_pred)\n",
    "print reg.score(X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = build_features(org_test_data)\n",
    "test_train = test.drop(['Id'],axis=1)\n",
    "test_result = final_gb.predict(xgb.DMatrix(test_train))\n",
    "submission = pd.DataFrame({\"Id\": test['Id'], \"Sales\": np.expm1(test_result)})\n",
    "submission.to_csv(\"my_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGB feature importances\n",
    "# Based on https://www.kaggle.com/mmueller/liberty-mutual-group-property-inspection-prediction/xgb-feature-importance-python/code\n",
    "import operator\n",
    "\n",
    "create_feature_map(features_train)\n",
    "importance = final_gb.get_fscore(fmap='xgb.fmap')\n",
    "importance = sorted(importance.items(), key=operator.itemgetter(1))\n",
    "\n",
    "df = pd.DataFrame(importance, columns=['feature', 'fscore'])\n",
    "df['fscore'] = df['fscore'] / df['fscore'].sum()\n",
    "\n",
    "featp = df.plot(kind='barh', x='feature', y='fscore', legend=False, figsize=(6, 10))\n",
    "plt.title('XGBoost Feature Importance')\n",
    "plt.xlabel('relative importance')\n",
    "fig_featp = featp.get_figure()\n",
    "fig_featp.savefig('feature_importance_xgb.png', bbox_inches='tight', pad_inches=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
